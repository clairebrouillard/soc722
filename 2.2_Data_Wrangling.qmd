---
title: "2.2 Data Wrangling"
author: "Claire Brouillard"
format: html
---
```{r}
library(nycflights13)
library(tidyverse)

```

# 3.2.5 Exercises
## 1
```{r}
flights |>
  filter(
    arr_delay > 120,
    dest == "IAH" | dest == "HOU",
    carrier == "UA" | carrier == "AA" | carrier == "DL",
    month == 7 | 8 | 9,
    sched_dep_time - dep_time <= 0,
    dep_delay >= 60 & dep_delay - arr_delay > 30
  )
```

## 2
```{r}
flights |>
  arrange(desc(dep_delay))

flights|> 
  arrange(dep_time)
```

## 3
```{r}
flights |>
  arrange(air_time)
```

## 4
```{r}
flights |>
  filter(year == 2013) |>
  distinct(month, day) |>
  count()

# Yes, there was a flight on every day of 2013. 
```

## 5
```{r}
flights |>
  arrange(desc(distance))
# Flights from JFK to HNL travel the farthest distance.

flights |>
  arrange(distance)
# There was one flight from EWR to LGA that traveled the shortest distance. 
```

## 6
Yes, filter() should be used before arrange() to ensure that the results are sorted properly. Filtering out the unwanted cases first allows the arrange() function to sort fewer cases instead of the entire data frame.

# 3.3.5 Exercises
## 1
I would expect the departure delay to represent the difference in departure time and scheduled departure time. 
```{r}
flights |>
  count()

flights |>
  mutate(chng_dep = dep_time - sched_dep_time) |>
  select(dep_delay = chng_dep) |>
  count()
```

## 2 FINISH THIS
```{r}
flights |>
  select(dep_time, dep_delay, arr_time, arr_delay)

flights |>
  select(starts_with("dep") | starts_with("arr"))

flights |>
  select(dep_time:arr_delay & !starts_with("sched"))

flights |>
  select(!year:day & !carrier:time_hour & !starts_with("sched"))
```

## 3
If you name the same variable twice in the select() call, it only appears once in the tibble.
```{r}
flights |>
  select(dep_time, arr_time, dep_delay, arr_time)
```

## 4
The any_of() function selects columns based on character vectors, so it would be helpful in selecting the columns from the flights data frame that are included in the variables vector.
```{r}
variables <- c("year", "month", "day", "dep_delay", "arr_delay")

flights |>
  select(any_of(variables))
```

## 5
```{r}
flights |> 
  select(contains("TIME"))

# Running the code returns the columns that contain "term", so select helpers aren't case sensitive.

flights |>
  select(contains("TIME", ignore.case = FALSE))

# Setting the argument ignore.case = FALSE makes the select helper case sensitive
```

## 6
```{r}
flights |>
  rename (air_time_min = air_time) |>
  relocate(air_time_min)
```

## 7
```{r}
# flights |> 
#  select(tailnum) |> 
#  arrange(arr_delay)

# This doesn't work because only tailnum has been selected so the arrange function cannot find arr_delay. To fix it, you'd have to include arr_delay in the original selection.

flights |>
  select(tailnum, arr_delay) |>
  arrange(arr_delay)
```

# 3.5.7 Exercises

## 1
It's incredibly difficult to disentangle the effects of bad airports vs. bad carriers because every flight has two airports (origin and destination). 
```{r}
flights |>
  group_by(carrier, dest) |>
  select(carrier, origin, dest, dep_delay, arr_delay) |>
  group_by(carrier, origin, dest) |>
  mutate(
    mean_delay = (dep_delay + arr_delay) / 2)
  
```

## 2
```{r}
flights |>
  select(flight, dest, dep_delay) |>
  group_by(dest) |>
  slice_max(dep_delay, n = 1)
```

## 3
```{r}
df <- flights |>
  select(flight, hour, minute, dep_delay) |>
  drop_na()
  
df$time_string <- paste(df$hour, df$minute, sep = ":")

departures <- df |>
  mutate(time = hms::parse_hm(time_string)) |>
  group_by(time) |>
  summarize(avg_delay = mean(dep_delay, na.rm = TRUE))

ggplot(departures, aes(x = time, y = avg_delay)) +
  geom_point() +
  labs(
    x = "Scheduled departure time",
    y = "Departure delay",
    title = "Average departure delay by scheduled departure time")
```

## 4
```{r}
flights |>
  filter(origin == "EWR",
         dest == "RDU",
         month == "1" | month == "2") |>
  drop_na() |>
  group_by(month, day) |>
  slice_min(dep_delay, n = 5)

flights |>
  filter(origin == "EWR",
         dest == "RDU",
         month == "1" | month == "2") |>
  drop_na() |>
  group_by(month, day) |>
  slice_min(dep_delay, n = -2)

# If you supply a negative n for a slice function, that many rows will be removed from the opposite end of the data frame (i.e., in this example where n=-2, the two maximum values are removed and the rest are printed). 
```

## 5

## 6
```{r}
df <- tibble(
  x = 1:5,
  y = c("a", "b", "a", "a", "b"),
  z = c("K", "K", "L", "L", "K")
)
```

### a
This will create two groups based on y (one for a and one for b), but will not change the order of the data frame. 
1 a     K    
2 b     K    
3 a     L    
4 a     L    
5 b     K  
```{r}
df |>
  group_by(y)
```
group_by() creates two groups based on y but does not change the order of the data frame.

### b
1 a     K    
3 a     L    
4 a     L    
2 b     K    
5 b     K   
```{r}
df |>
  arrange(y)
```
arrange() arranges the data frame based on y in alphabetical order. This is different from group_by() because it changes the order of the rows in the data frame but does not create groups.

### c
a   2.67       
b   3.5
```{r}
df |>
  group_by(y) |>
  summarize(mean_x = mean(x))
```
The pipleine groups by y and then finds the mean for each group (a and b) based on the x column of integers.

### d
a K   1
a L   3.5
b K   3.5
```{r}
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))
```
This pipeline groups by y and then z, creating three groups (a x K, a x L, and b x K). Then the pipeline finds the mean based on the x column of integers.

### e
a K   1
a L   3.5
b K   3.5
```{r}
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x), .groups = "drop")
```
This pipleine does the same thing as the previous one except it ungropus the results.

### f
a K   1
a L   3.5
b K   3.5

1 a     K        1  
2 b     K        3.5
3 a     L        3.5
4 a     L        3.5
5 b     K        3.5
```{r}
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))

df |>
  group_by(y, z) |>
  mutate(mean_x = mean(x))
```
The first pipeline groups by y and z and then finds the mean for each group, while the second pipeline groups by y and z but then finds the mean for each x value within each group. 
